\documentclass[12pt, a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{hyperref} 
\title{Machine Learning Course Project}

\begin{document}
    %\maketitle
    %\tableofcontents
    \section{Problem formulation}
    \subsection{Application of ML Problem}
    The current winter has shown that slippery weather might come as a surprise.
    However, when slippery conditions are expected during the day, a service called \href{https://liukastumisvaroitus.fi/en/}{Liukastumisvaroitus} (Slipping warning) sends subscribers a text-message.

    According to the website, the slippery condition is identified by humans.
    Though one could think that these dangerous weather conditions can be predicted without 
    human knowledge, but to what level of accuracy? This makes it a great target for testing machine learning as an application.
    
    Ideally the machine learning application could predict, given the current weather conditions, whether the slippery warning would be raised.

    The data point is going to be a daily observation of weather data, with the additional
    slippery warning parameter. In other words, a single data point represents the weather conditions of a day. Data includes all data points (daily observations) from around 
    November 2013, as the earliest records of slipping warnings are from then.

    Concluding the parameters, 
    \begin{itemize}
      \item Potential features for the application could be \textit{Precipitation amount}, \textit{Air temperature} and \textit{Snow depth}. All of these properties are numerical and are easily measureable.
      \item The label of the application is going to be whether the \textit{slippery warning} would be raised, with values 0/1.
    \end{itemize}
    

    \subsection{Data sources}
    The slipping warning service offers an \href{https://liukastumisvaroitus-api.beze.io/api/v1/warnings/}{API (link)} for historical data analysis. Some 600 warnings have been issued in total since October 2011.
    %The slipping warning can be seen to be given at any point during the day, though most usually in the night hours.
    As the slipping warning service data only consists of a timestamp and the city issued, training the machine learning algorithm to account for the current weather conditions needs more data to work with.
    Additionally, the slipping warnings are given on city level for Lahti, Oulu, Kuopio, Jyväskylä, Helsinki, and Joensuu.

    Thus, historical weather data from the \href{https://en.ilmatieteenlaitos.fi/download-observations}{Finnish Metheorological Institute (link)}
    is combined. Although FMI offers hourly historical data, in this project, the plan is to use the daily aggregated weather recordings for simplicity.
    In total, there are some 3800*6=22800 daily weather reports since October 2011. Applied amount will be lower, as we're concentrated on winter time only.
    The FMI data includes air temperature (min/max/overall), ground temperature, precipitation amount and snow depth, which can be used as features in this project.

    Combined together based on the city and the timestamp, these data sources will be used to train and validate the machine learning algorithm. The labels and features are extracted from the sources and used as explained in the \hyperlink{section.0.1.1}{introduction section}.

    \section{Methods}
    \subsection{Feature selection}
    When you think what causes the most dangerous slipping conditions outside, two conditions need to apply:
    \begin{itemize}
      \item There need to be ice on the road.
      \item There need to be water on the road.
    \end{itemize}
    These conditions are the result of a weather that's around 0°C in temperature and the environment is snowy or there's waterfall happening.
    Thus, features selected are \textbf{Air temperature}, \textbf{Precipitation amount} and \textbf{Snow depth}. Empirical feature analysis 
    and comparison using my ML script and Excel back up these selections. 

    Feature candidates, such as Ground level minimum temperature, was cut off due to lack of data.
    Minimum and maximum daily temperature were not deemed to provide additional value over the simplicity 
    of the aggregated daily temperature value.

    \subsection{Model}
    \subsubsection{Loss function}
    \subsection{Data set construction}
    As the amount of slipping warnings is quite low compared to the actual weather observations (600 < 17500), performng a random split once might lead to 
    very polarised results regarding the contained warnings. Thus, k-fold approach is used to mitigate the random split variations better.

    Training and validation data is splitted with the k-fold approach. K-fold runs the training and validation cycle multiple times for different
    subsets of the data. Data consists of some 17500 data points, which is splitted in to 5 folds as it is the default in the sklearn utility. 
    Folding 5 times results in a training set of 14000 data points and a validation set of 3500 data points in each run.


    % Temperatures were filtered from outliers -10 or greater than 10.

    \newpage

    \section{Appendices}
    \begin{itemize}
      \item Code and resources are available on the github page: \href{}{Link}.
    \end{itemize}



\end{document}
